# -*- coding: utf-8 -*-
"""ML with python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FWvIWfuPNhXEN1unLICJTV1xuzGJHxmg
"""

class Parent:
  colour = "Black"
  relation = "parents"

  def work(self):
    print("we are working forming")

class Childrens(Parent):
  study = "BCA"
  location = "Chikodi"

  def Education(self,USN_Number):
    print("I am studying in BK college Chikodi",USN_Number)

obj = Childrens()
print(obj.relation)
obj.Education("U15DO25S0004")
obj.work()
print(obj.location)
print(obj.colour)
print(obj.study)
print("We are studying ",obj.study,"course")

import numpy as np

import pandas as pd

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

<>

from sklearn.linear_model import LinearRegression

data = pd.DataFrame({

"Ice_creame" : [10, 20, 25, 40, 45, 50, 55, 60], "Price": [40, 60, 100, 120, 150, 175, 190, 210]

})

x = data["Ice_creame"]

y = data["Price"]

x_train,x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state = 42)

model LinearRegression()

model.fit(x_train,y_train)

print(model.predict(x_test))

print(y_test)

Search

P



class Father:
  Age = 45
  Name = "ABC"

  def work(self):
    print("My Father is working in my village")

class Mother:
  colour = "Black"
  place = "Chikodi"

  def WORK(self):
    print("My mom is a Teacher")


class Child(Father,Mother):
  Study = "BCA"
  Address = "Belagavi"

  def course(self):
    print("I'm studying BCA in National College Belagavi")
obj = Child()
obj.WORK()
print(obj.Study)
obj.course()
obj.work()
print("My Father age is",obj.Age)

class GrandFather:
  Age = 70
  name = "XYZ"

  def woRK(self):
    print("Retaired GOVT Officer ")

class GrandMother:
  NAME = "PWD"

  def WOrk(self):
    print("House wife")

class Father:
  Age = 45
  Name = "ABC"

  def work(self):
    print("My Father is working in my village")

class Mother:
  colour = "Black"
  place = "Chikodi"

  def WORK(self):
    print("My mom is a Teacher")


class Child(Father,Mother):
  Study = "BCA"
  Address = "Belagavi"

  def course(self):
    print("I'm studying BCA in National College Belagavi")

class Grand_Parents:
  def Method1(self):
    print("ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—ðŸš—")

class Parents(Grand_Parents):
  def Method2(self):
    print("ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸ðŸï¸")

class Childrens(Parents):
   def Method3(self):
    print("ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²ðŸš²")


obj = Childrens()
obj.Method1()
obj.Method2()
obj.Method3()

class A:
  def fun1(self):
    print("**********")

class B(A):
  def fun2(self):
    print("$$$$$$$$$$")

class C(A):
  def fun3(self):
    print("!!!!!!!!!!")

obj1 = B()
obj2 = C()
obj1.fun2()
obj1.fun1()
obj2.fun1()
obj2.fun1()





from abc import ABC, abstractmethod

class Vehicle(ABC):
  def cost(self):
    print("Total cost is 45Lakh")

  car_colour="Silever"

  def speed(self):
    pass

class car(Vehicle):
  year = 1970
  def speed(self):
    print("Car is goinh 60km per hour")

  def company(self):
    print("The car company name is fortuner")
obj = car()
obj.speed()
obj.cost()
print(obj.car_colour)
print(obj.year)

marks = [78,65,90,55,82]
print(marks)

D=[1012,"prajwal",9.20,True]
print(D)
print(D[-1:-4])

csv_data = """name,marks,atttendence
ravi,78,85
anu,65,78
raj,90,95
"""

with open("student.csv","w") as f:
  f.write(csv_data)

print("student.csv created successfully")

import csv

with open("student.csv","r") as file:
  reader = csv.reader(file)
  for row in reader:
    print(row)

marks=[50,70,60,80,90]
print(marks)
print(type(marks))
print(len(marks))
marks.append(60)
print(marks)
marks.append(50)
print(marks)
print(marks.remove(70))
print(marks)
print(marks.count(60))
print(marks.pop())
marks.insert(0,20)
print(marks)
marks.sort()
print(marks)
print(marks[4])
print(marks.index(90))
marks.reverse()
print(marks)
print(marks[2:5])
print(marks.clear())
print(marks)

marks = (12,45,67,34,78,95)
print(marks)
print(type(marks))
print(len(marks))
print(marks.index(78))
print(marks[5])
print(marks[1:5])
print(marks.index(45))
print(min(marks))
print(max(marks))
print(sum(marks))

example = {
    "USN Number" : 111,
    "Name"       : "omkar",
    "Gender"     : "Male",
    "Address"    : "raibag"
}
print(example)
print(len(example))
print(type(example))
example["pincode"] = 584128
print(example)
example["age"] = 26
print(example)
print(example["Name"])
example["Address"]="raibag"
print(example)
print(example.get("age"))
print(example.pop("Gender"))
print(example.popitem())
print(example)
print(example.keys())
print(example.values())
print(example.items())


print(example.update({"college":"city college raibag"}) )
print(example)
del example["pincode"]
print(example)
example.clear()
print(example)

example = {
    "Reg Number" : 110015,
    "Name"       : "omkar",
    "Gender"     : "Male",
    "Address"    : "raibag"
     b
}
print(example)
print(len(example))
print(type(example))
example["pincode"] = 584128
print(example)
example["age"] = 26
print(example)
print(example["Name"])
example["Address"]="raibag"
print(example)
print(example.get("age"))
print(example.pop("Gender"))
print(example.popitem())
print(example)
print(example.keys())
print(example.values())
print(example.items())


print(example.update({"college":"city college raibag"}) )
print(example)
del example["pincode"]
print(example)
example.clear()
print(example)

import math
print(math.sqrt(169))
print(math.pow(2,3))
print(math.factorial(6))
print(math.pi)
print(math.ceil(8))

import random
print(random.randint(1,10))
print(random.random())
print(random.choice(["pen","paper","mobile"]))

import calendar
print(calendar.month(2025,10))
print(calendar.isleap(2028))

import calendar
year = 2026
for month in range(1,12+1):
  print(calendar.month(year,month))

file=open("result.txt","w")
file.write("Ravi - pass\nAnu - pass\nRaj - pass")
file.close()
print("result.txt file is successfully created")

file=open("result.txt","r")
content = file.read()
print(content)
file.close()

csv_data = """name,marks,attendance
ravi,78,85
anu,65,78
raj,90,95
"""

with open("student.csv","w") as f:
  f.write(csv_data)

print("student.csv created successfully")

import csv

with open("student.csv","r") as file:
  reader = csv.reader(file)
  next(reader)

  for row in reader:
    name = row[0]
    marks = row[1]
    print(name,marks)

import csv

with open("New_students.csv","w",newline="") as file:
  writer = csv.writer(file)
  writer.writerow(["name","marks","attendance"])
  writer.writerow(["Amit",88,92])
  writer.writerow(["Sita",76,85])

pip install pandas

import pandas as pd

data = pd.read_csv("student.csv")
print(data)

import pandas as pd

data = pd.read_csv("student.csv")
print(data["marks"])
print(data["attendance"])
print(data["marks"],["attendance"])

import numpy as np12
marks_list = [78,65,90]

marks_array = np.array([78,65,90])

print(type(marks_list))
print(type(marks_array))

marks = np.array([78,65,90,55])
print(marks)
update_marks = marks+5
print(update_marks)

marks = np.array([78,65,90,55,82])

print("Average:",marks.mean())
print("Minimum:",marks.min())
print("Maximum:",marks.max())

import numpy as np
student = np.array([
    [78,85],
    [65,70],
    [90,95]
   ])
print(student)

csv_data = """name,marks,attendance
ravi,78,85
anu,65,78
raj,90,95
"""

with open("student.csv","w") as f:
  f.write(csv_data)

print("student.csv created successfully")

import pandas as pd

data = pd.read_csv("student.csv")
print(data)

csv_data = """name,marks,attendance
ravi,78,85
anu,65,78
raj,90,95
"""

with open("student.csv","w") as f:
  f.write(csv_data)

print("student.csv created successfully")

import pandas as pd
data = pd.read_csv("student.csv")
print(data)
print(type(data))
print(data[["name","attendance"]])

import pandas as pd
data = (pd.read_csv("student.csv"))
print(data.head())
print(data.shape)
print(data.describe())

import pandas as pd

data = pd.DataFrame ({
    "name": ["ravi","anu","raj"],
    "marks": [78,None,90]
})
print(data)
data["marks"] = data["marks"].fillna(data["marks"].mean())
data["marks"].fillna(data["marks"].mean(),inplace = True)
print(data)

import pandas as pd
import numpy as np

marks = np.array([78,65,90,55])
df = pd.DataFrame(marks,columns=["marks"])
print(df)

csv_data = """name,marks,attendance
ravi,78,85
anu,65,78
raj,90,95
"""

with open("student.csv","w") as f:
  f.write(csv_data)

print("student.csv created successfully")

import pandas as pd

data = pd.read_csv("student.csv")
avg = data["marks"].mean()

print("Average Marks:",avg)

print("Above average students:")
print(data[data["marks"]>avg])

import pandas as pd

data = pd.DataFrame ( {
    "name":["ravi","anu","raj","ravi"],
    "marks":[78,None,200,78],
    "attendance": [85,70,None,85]
  })
print(data)

print(data.isnull())
print(data.isnull().sum())

data["marks"].fillna(data["marks"].mean(),inplace = True)
data["attendance"].fillna(data["attendance"].mean(),inplace = True)
print(data)

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

data = pd.DataFrame ({
    "marks":[78,65,40,90,55,88,30,72],
    "attendance":[85,70,55,95,60,92,50,80],
    "result":[1,1,0,1,0,1,0,1]
  })

x = data[["marks","attendance"]]
y = data["result"]

x_train,x_test,y_train,y_test = train_test_split(
     x,y, test_size=0.2, random_state=42
 )


module = LogisticRegression()
module.fit(x_train,y_train)

accurancy = module.score(x_test,y_test)
print("Accurancy:",accurancy)


pass_students = data[data["result"]==1]
fail_students = data[data["result"]==0]

plt.figure(figsize=(8, 6))

plt.scatter(pass_students["marks"],pass_students["attendance"],label="Pass")
plt.scatter(fail_students["marks"],fail_students["attendance"],label="Fail")


plt.xlabel("Marks")
plt.ylabel("Attendance")
plt.title("Student Result Classification(Pass VS Fail)")
plt.legend()

plt.show()

import pandas as pd

data = pd.DataFrame ( {
    "name":["ravi","anu","raj","ravi"],
    "marks":[78,None,200,78],
    "attendance": [85,70,None,85]
  })
print(data)
print("====================")
data.drop_duplicates(inplace = True)
print(data)
print("====================")
data.dropna(inplace=True)
print(data)
print("====================")
data.dropna(inplace=True)
print(data)

data = data[data["marks"]<= 100]
print(data)



data["marks"] = data["marks"].astype(int)
print(data.dtypes)

data = pd.DataFrame({
    "gender": ["Male","Female","Female","Male"],
    "marks": [78,65,90,55]
})
print(data)
print("___________________")
data["gender"] = data["gender"].map({"Male":0,"Female":1})
print(data)

csv_data = """name,marks,attendance
ravi,78,85
anu,65,78
raj,90,95
"""

with open("student.csv","w") as f:
  f.write(csv_data)

print("student.csv created successfully")

#
#
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

data = pd.DataFrame({
    "Marks":[78,65,35,90,50],
    "Attendance":[85,70,40,95,55],
    "Result":["Pass","Pass","Fail","Pass","Pass"]
})
print(data)
print("==============================")
#read data
#clear and processing data

data["Result"] = data["Result"].map({"Pass":1,"Fail":0})
print(data)
print("===============================================")

print(data.describe())
x = data[["Marks","Attendance"]]        #feature / input values
y = data["Result"]                      #label / output values
print("=======================================")
print(x)
print("===================")
print(y)

x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2)
print("==================================================")
print(x_train)
print("====================================")
print(x_test)
print("==================================================")
print(y_train)
print("====================================")
print(y_test)

model = LogisticRegression()
model.fit(x_train,y_train)

print(model.predict(x_test))
print("===============================")
print(y_test)

import pandas as pd
data = pd.DataFrame({
    "names":["ravi","anu","raj","sita","amit"],
    "marks":[78,65,90,55,88],
    "attendance":[85,70,95,60,92]
})
print(data)

print(data.shape)
print(data.columns)
print(data.head())
print(data.describe())
print(data.isnull().sum())
print(data["marks"].mean())
print(data["marks"].max())
print(data["marks"].min())
print(data["attendance"].mean())
print(data["attendance"].max())
print(data["attendance"].min())
weak_students=data[data["marks"]<60]
print(weak_students)
top_students=data[data["marks"]>85]
print(top_students)
print(data[["marks","attendance"]].corr())

import matplotlib.pyplot as plt

plt.scatter(data["attendance"],data["marks"])
plt.xlabel("attendance")
plt.ylabel("marks")

plt.title("ATTANDANCE VS MARKS")
plt.grid()
plt.show()

import numpy as np
rows = np.array(["A","B","C","D","E","F"])
column = np.array([4,8,2,7,9,11])
plt.bar(rows,column,color = "lightpink",edgecolor = "black")
plt.show

data = pd.DataFrame({

"Ice_creame" : [10, 20, 25, 40, 45, 50, 55, 60],

"Price": [40, 60, 100, 120, 150, 175, 190, 210]


})

x = data[["Ice_creame"]]

y = data["Price"]

x_train,x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state = 42)

Obj = LinearRegression()

Obj.fit(x_train,y_train)

print("Prediction is:", Obj.predict(x_test))

print(y_test.values)

plt.scatter(x, y)

plt.plot(x, Obj.predict(x))

plt.show()

import numpy as np
import matplotlib.pyplot as plt

things = np.array(["battery","charger","screen guard","backcover"])
price = np.array([400,300,200,150])
plt.bar(things,price,color = "skyblue",edgecolor = "red")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

marks = [20,40,30,50,70,60,90,80]
plt.hist(marks,bins=6,edgecolor = "black")
plt.show()

import matplotlib.pyplot as plt
Hours = [8.0,8.30,9.0,9.30,10.0,11.0,12.0,1.0]
temp = ["20C","25C","28C","30C","25C","33C","35C","33"]

plt.plot(Hours,temp)
plt.grid()
plt.show()

import matplotlib.pyplot as plt

sub = ["C Program","DBMS","Maths","Accountancy","Kannada","English"]
marks = [72, 55, 60, 78, 75, 45]
plt.pie(marks, labels=sub, autopct='%1.1f%%')
plt.show()

import matplotlib.pyplot as plt

hours = [2,3,4,5,6,7,8,9]
marks = [40,50,60,68,74,80,90,97]

plt.scatter(hours,marks, color="red")
plt.show()

import matplotlib.pyplot as plt
salary = [20000,25000,30000,35000,40000]
plt.boxplot(salary)
plt.title("Salary Distribution")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

data = np.array([
    [10,20,30,],
    [30,40,50],
    [40,50,60]
])
plt.imshow(data)
plt.colorbar()
plt.show()

import matplotlib.pyplot as plt

year = [2020,2021,2022,2023,2024,2025]
population = [100000,150000,180000,200000,280000,350000]
plt.fill_between(year,population)
plt.title("Population")
plt.xlabel("Year")
plt.ylabel("Population")
plt.show()

import matplotlib.pyplot as plt

overs = [1,2,3,4,5,6]
score = [10,13,20,18,22,32]

size = [500,700,250,800,940,1070]

plt.scatter(overs,score,s = size,color = "purple")
plt.show()

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
data = pd.DataFrame({
    "Exp":[1,2,3,4,5,6,7,8],
    "salary":[20000,250000,30000,35000,40000,45000,50000,60000]
})

print(data)

x = data[["Exp"]]
y = data[["salary"]]

x_train,x_test, y_train, y_test = train_test_split(x,y, test_size=0.25)
EX = LinearRegression()

EX.fit(x_train,y_train)

#print("Prediction of x_test values is:",EX.predict(x_test))
#print("Prediction of y_test values is:",EX.predict(y_test))
print("Prediction values is:",EX.predict(x_test))
print("Prediction values is:",EX.predict([[10]]))
plt.scatter(x,y)
plt.plot(x,EX.predict(x))
plt.xlabel("Exrerience")
plt.ylabel("Salary")
plt.title("Experience vs Salary")
plt.legend()
plt.grid()
plt.show()

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
data = pd.DataFrame({
    "Exp":[1,2,3,4,5,6,7,8],
    "salary":[20000,250000,30000,35000,40000,45000,50000,60000]
})

print(data)

x = data[["Exp"]]
y = data[["salary"]]

x_train,x_test, y_train, y_test = train_test_split(x,y, test_size=0.25)
EX = LinearRegression()

EX.fit(x_train,y_train)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
x = np.array([ # Area Rooms  Rent
              [1000,  4,    10000],
              [1500,  5,    12000],
              [1200,  5,    11000],
              [2000,  6,    20000],
              [1700,  6,    17000]
        ])
y=np.array([8,15,10,20,17])
print(x)
print("=================================")
print(y)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)
print("=================================")
obj=LinearRegression()
obj.fit(x_train,y_train)
print("prediction is :",obj.predict(x_test))

new_values = [[2500,8,25000]]
print("prediction of new land values is :",obj.predict(new_values))

import numpy as py
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
import math

data = pd.DataFrame ({
    "Quantity":[1,2,3,4,5,6,7,8],
    "Price":[100,200,300,400,500,600,700,800]
})

print(data)

x = data[["Quantity"]]
y = data[["Price"]]

x_train,x_test, y_train, y_test = train_test_split(x,y, test_size=0.1)

obj = LinearRegression()
obj.fit(x_train,y_train)

prediction = obj.predict(x_test)
print("Prediction Value is: ",prediction)

MAE = mean_absolute_error(y_test,prediction)
print("Mean Absolute error is:",mean_absolute_error(y_test,prediction))
print(MAE)

MSE = mean_squared_error(y_test,prediction)
print("Mean Squared error is:",mean_squared_error(y_test,prediction))

RMSE = math.sqrt(MSE)
print("Roor mean squared error is:",RMSE)

R2 = r2_score(y_test,prediction)
print("R2 Score error is:",R2)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

data = pd.DataFrame ({
    "msg": [10,8,15,13,45,5,50,12],
    "len":[50,30,60,25,70,20,80,35],
    "result": [0,1,0,1,0,1,0,1]
})
print(data)

x = data[["msg","len"]]
y = data["result"]

x_train,x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)

obj = LogisticRegression()
obj.fit(x_train, y_train)

prediction = obj.predict(x_test)
print("Prediction value is :",obj.predict(x_test))

accurancy = obj.score(x_test, y_test)
print("Accurancy is:",accurancy)

new_values = [[20,45,]]
print("Prediction of new values is :",obj.predict(new_values))

if prediction[0] == 1:
  print("Spam")
else:
  print("Not Spam ")

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accracy_score, precision_score, recall_score
x np.array([
    [2,60],
    [4,65],
    [6,70],
    [8,80],
    [10,90],
    [1,50],
    [3,55],
    [7,75],
])

y = np.array([0,0,1,1,1,0,0,1])

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)

knn =

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
import matplotlib.pyplot as plt

np.random.seed(0)
X = 2 * np.random.rand(20,1)
Y = 3 * x**2 + np.random.randn(20,1) * 0.5


X_train = X
Y_train = Y

p = PolynomialFeatures(degree = 8)
X_poly = p.fit_transform(X_train)

model = LinearRegression()
model.fit(X_poly,Y_train)

X_range = np.linspace(0,2,200).reshape(-1,1)
X_range_poly = p.transform(X_range)

Y_overfit_poly = model.predict(X_range_poly)

plt.scatter(X,Y,label = "Data")
plt.plot(X_range,Y_overfit_poly, label = "Overfit Model",color = "red")
plt.legend()
plt.show()

# confussion matrics
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score

x_actual = [ 1, 0, 1, 0, 1, 0, 1, 1]
y_pred = [ 0, 1, 1, 0, 1, 0, 1, 1]

cm = confusion_matrix(x_actual, y_pred)

print("Accurancy score value is:",accuracy_score(x_actual,y_pred))
print("Precision score value is:",precision_score(x_actual,y_pred))
print("Recall score value is:",recall_score(x_actual,y_pred))
print("F1 score value is:",f1_score(x_actual,y_pred))

plt.figure()
plt.imshow(cm)

for i in range(len(cm)):
  for j in range(len(cm[0])):
   plt.text(j,i,cm[i][j], ha = "center", color = "white")

plt.xticks([0,1])
plt.yticks([0,1])
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

X = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])
y = np.array([0, 0, 0, 0, 1, 1, 1, 1])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))

plt.scatter(X, y)
plt.plot(X, model.predict(X), color="red")
plt.xlabel("X values")
plt.ylabel("Class (0 or 1)")
plt.title("Logistic Regression")
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

Data = pd.DataFrame({
    "Overs": [5, 6, 7, 8, 9, 10],
    "Runs": [5, 10, 15, 20, 25, 30]
})

print(Data)

# Define X and y
X = Data[["Overs"]]
y = Data["Runs"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

BCA = LinearRegression()

BCA.fit(X_train, y_train)

pred = BCA.predict(X_test)

print("X_test values:", X_test)
print("Predicted values:", pred)

rows=np.linspace(5, 35, 100).reshape(-1,1)

plt.scatter(X, y)
plt.plot(X, BCA.predict(X), color="red")
plt.xlabel("Overs")
plt.ylabel("Runs")
plt.title("Linear Regression")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

x = np.array([

[1, 2],

[1, 4],
[1, 0],
[10, 2],
[10, 4],
[10, 0],
])
KMeans = KMeans(n_clusters=2, random_state=0)
KMeans.fit(x)

labels = KMeans.labels_
centroids = KMeans.cluster_centers_

print("Cluster labels:", labels)

print("Centroids:",centroids)

plt.scatter(x[:, 0], x[:, 1])
plt.scatter(centroids[:,0], centroids[:,1], marker ='X', s = 1500)
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.title("Unsupervised Learning-KMeans Clustering")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

iris = datasets.load_iris()
print(iris)

x = iris.data[:,:2]
y = iris.target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

model = SVC(kernel ='linear')
model.fit(x_train, y_train)

y_pred = model.predict(x_test)
print("Accuracy:",accuracy_score(y_test, y_pred))

x_min, x_max =x[:,0].min() - 1, x[:,0].max() + 1
y_min, y_max =x[:,1].min() - 1, x[:,1].max() + 1

xx, yy = np.meshgrid(
    np.linspace(x_min, x_max,200),
    np.linspace(y_min, y_max,200)
)

z = model.predict(np.c_[xx.ravel(), yy.ravel()])
z = z.reshape(xx.shape)

plt.contourf(xx,yy,z,alpha=0.3)

plt.scatter(x[:,0], x[:,1], c=y)

plt.xlabel("Sepal Length")
plt.ylabel("Sepal Width")
plt.title("SVM Decision Boundary")
plt.show()

#1)
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.DataFrame({
    "s_hours":[1,2,3,4,5,6,7,8],
    "marks":[30,35,40,45,50,55,60,65]
})
print(data)

sns.scatterplot(x = "s_hours", y= "marks",data = data)
plt.xlabel("Study Hours")
plt.ylabel("Marks")
plt.title("Student study Hourd Vs Marks")
plt.show()

#2)
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

data = pd.DataFrame({
    "Age" : [25, 45, 35, 50, 23, 40, 60, 48, 33, 55 ],
    "BP" : [120, 140, 130, 150, 110, 135, 160,145, 160, 155],
    "Disease" : [0, 1, 0, 1, 0 ,1, 1, 1, 0, 1]

  })

x = data[["Age","BP"]]
y = data["Disease"]

obj = RandomForestClassifier()
score = cross_val_score(obj, x, y, cv=5)
print("Cross value validation score is :", score)
print("average of Score value is :", score.mean())

#3)from sklearn. preprocessing import standardScaler

import pandas as pd
from sklearn.preprocessing import StandardScaler
import pandas as pd

data = pd.DataFrame({
 "Exp":[1,2,3,4,5],
 "Age":[22,25,30,35,40]
})

print("Actual data's", data)

obj = StandardScaler()
data = obj.fit_transform (data)

print("Scaled Data's:", data)

#4)from sklearn.ensemble impot RandomForestClassifier

import pandas as pd
from sklearn.ensemble import RandomForestClassifier


data = pd.DataFrame({
"income":[30000,40000,50000,60000,70000],
"c_score":[600,500,700,750,800],
"loan":[0,0,1,1,1]
})
print(data)
#print(data.shape)
#print(data[data["c_score"] >= 700])

x = data[["income","c_score"]]
y = data["loan"]

obj = RandomForestClassifier(n_estimators=50,random_state=42)

obj.fit(x, y)

print("Prediction of actual value is:", obj.predict(x))

n_value = [[25000,400]]

print("New value prediction is:", obj.predict(n_value))

print("Loan is not approved")

#Smart Workforce Analytics using Machine Learning

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegresstion, LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_metrics,mean_squared_error,r2_score

np.random.seed(42)

data = pd. DataFrame({
"Experience":np.random.randint(1,15,250),
"EducationLevel":np.random.randint(1,5,250),
"ProjectHandled":np.random.randint(1,20,250),
"WorkingHours":np.random.randint(6,12,250),
"PerformanceScore":np.random.randint(1,6,250),
})


data["Salary"]=(
data["Experience"]*5000+
data["EducationLevel"]*8000+
data["ProjectHandled"]*1500+
data["performanceScore"]*4000+
np.random. randint (-10000,10000,250)
)

data["Attrition"] = np.where (
   (data["WorkingHours"]>10)&
   (data["PerformanceScore"]<3),1,0
)

print("Dataset Preview:\n", data.head())

plt.figure()
plt.scatter(data["Experience"],data["Salary"])
plt.title("Experience VS Salary")
plt.xlabel("Experience")
plt.ylabel("Salary")
plt.show()

plt.figure()
sns.heatmap(data.corr(), annot = True, cmap="coolwarm")
plt.title("Featured Correlation")
plt.show()

X_reg = data.drop(["Salary", "Attrition"], axis=1)
y_reg = data["Salary"]

X_train, X_test, y_train, y_test = train_test_split(
    X_reg, y_reg, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train_r = scaler.fit_transform(X_train_r)
X_test_r = scaler.transform(X_test_r)

reg_model=LinearRegresstion()
reg.fit(X_train_r, y_train_r)

y_pred_r = reg_model.predict(X_test_r)

print ("\nSalary Prediction Results")
print ("R2 Score:", r2_score(y_test_r, y_pred_r))
print ("RMSE:",np.sqrt(mean_squared_error(y_test_r, y_pred_r)))


plt.figure()
plt.scatter(y_test_r, y_pred_r)
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.title("Actual VS Predicted Salary")
plt.show()


X_clf = data.drop(["Salary", "Attrition"], axis=1)

y_clf = data["Attrition"]

X_train_c, X_test_c, y_train_c, y_test_c = train_test_split( X_clf, y_clf, test_size=0.3, random_state=42

)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_c, y_train_c)

y_pred_c = rf_model.predict(X_test_c)

print("\nAttrition Prediction Results")

print("Accuracy:", accuracy_score(y_test_c, y_pred_c))

print("Confusion Matrix:\n", confusion_matrix(y_test_c, y_pred_c))

cv_score = cross_val_score(rf_model, X_clf, y_clf, cv=5)

print("Cross Validation Accuracy:", cv_score.mean())

importance = rf_model.feature_importances_

features = X_clf.columns

plt.figure()

plt.bar(features, importance)

plt.xticks(rotation=45)

plt.title("Feature Importance- Attrition Model")

plt.show()

print("\nProject Completed Successfully!")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import r2_score, accuracy_score, confusion_matrix

np.random.seed(42)

data = pd.DataFrame({
    "Experience": np.random.randint(1, 15, 250),
    "EducationLevel": np.random.randint(1, 5, 250),
    "ProjectsHandled": np.random.randint(1, 20, 250),
    "WorkingHours": np.random.randint(6, 12, 250),
    "PerformanceScore": np.random.randint(1, 6, 250)
})

# Salary Formula (Regression Target)
data["Salary"] = (
    data["Experience"] * 5000 +
    data["EducationLevel"] * 8000 +
    data["ProjectsHandled"] * 1500 +
    data["PerformanceScore"] * 4000 +
    np.random.randint(-10000, 10000, 250)

data["Attrition"] = np.where(
    (data["WorkingHours"] > 10) &
    (data["PerformanceScore"] < 3), 1, 0
)

print(data.head()

plt.figure()
sns.countplot(x="Attrition", data=data)
plt.title("Employee Attrition Count")
plt.show()

plt.figure()
sns.boxplot(x="Attrition", y="WorkingHours", data=data)
plt.title("Working Hours vs Attrition")
plt.show()

plt.figure()
sns.histplot(data["Salary"], bins=20, kde=True)
plt.title("Salary Distribution")
plt.show()

X_reg = data.drop(["Salary", "Attrition"], axis=1)
y_reg = data["Salary"]

X_train, X_test, y_train, y_test = train_test_split(
    X_reg, y_reg, test_size=0.2, random_state=42
)

reg_model = LinearRegression()
reg_model.fit(X_train, y_train)

y_pred = reg_model.predict(X_test)

print("R2 Score (Salary Prediction):", r2_score(y_test, y_pred))

X_clf = data.drop(["Salary", "Attrition"], axis=1)
y_clf = data["Attrition"]

X_train, X_test, y_train, y_test = train_test_split(
    X_clf, y_clf, test_size=0.2, random_state=42
)

clf_model = RandomForestClassifier(n_estimators=100, random_state=42)
clf_model.fit(X_train, y_train)

y_pred = clf_model.predict(X_test)

print("Accuracy (Attrition Prediction):", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

#Smart Workforce Analytics using Machine Learning
#step-1
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.linear_model import LinearRegression,LogisticRegression
from sklearn.metrics import accuracy_score,precision_score,confusion_matrix
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

np.random.seed(42)

#step -2
data = pd.DataFrame({
    "Experience" : np.random.randint(1,15,250),
    "EducationalLevel" :np.random.randint(1,5,250),
    "ProjectsHandled" :np.random.randint(1,20,250),
    "WorkingHours" :np.random.randint(1,12,250),
    "PerformanceScore" :np.random.randint(1,6,250),

    })

#step - 3
data["Salary"] = (
    data["Experience"] * 5000 +
    data["EducationalLevel"] * 8000 +
    data["ProjectsHandled"] * 1500 +
    data["PerformanceScore"] * 4000 +
    np.random.randint(-10000,10000,250)
)

#Attrition formula
data["Attrition"] = np.where(
    (data["WorkingHours"] > 10) &
    (data["PerformanceScore"] < 3) ,1 ,0

)

print("Dataset Preview:\n",data.head())

#step -3
#plot 1:Exp vs Sal
plt.figure()
plt.scatter(data["Experience"],data["Salary"])
plt.xlabel("Experience")
plt.ylabel("Salary")
plt.title("Experience vs Salary")
plt.show()

#plot 2: Attrition count
plt.figure()
data["Attrition"].value_counts().plot(kind="bar")
plt.title("Attrition Distribution")
plt.show()

#plot 3 :correlation Heatmap
plt.figure()
sns.heatmap(data.corr(),annot=True,cmap="coolwarm")
plt.title(" Feature Correlation")
plt.show()

#step - 4
x_reg = data.drop(["Salary","Attrition"], axis=1)
y_reg = data["Salary"]

x_train_r,x_test_r,y_train_r,y_test_r = train_test_split(x_reg, y_reg, test_size=0.3, random_state=42)

scaler = StandardScaler()
x_train_r = scaler.fit_transform(x_train_r)
x_test_r = scaler.transform(x_test_r)

reg_model = LinearRegression()
reg_model.fit(x_train_r,y_train_r)

y_pred_r = reg_model.predict(x_test_r)

print("\nSalary Prediction result")
print("R2 Score:", r2_score(y_test_r, y_pred_r))
print("RMSE:", np.sqrt(mean_squared_error(y_test_r, y_pred_r)))

#plot -4 : Actual VS Predicated Salary
plt.figure()
plt.scatter(y_test_r,y_pred_r)
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.title("Actual vs Predicted Salary")
plt.show()

 #step - 5:
x_clf = data.drop(["Salary","Attrition"], axis=1)
y_clf = data["Attrition"]

x_train_c,x_test_c,y_train_c,y_test_c = train_test_split(x_clf, y_clf, test_size=0.3, random_state=42)

rf_model = RandomForestClassifier(n_estimators=100,random_state=42)
rf_model.fit(x_train_c,y_train_c)

y_pred_c = rf_model.predict(x_test_c)

print("\nAttrition Prediction result")
print("Accuracy :", accuracy_score(y_test_c, y_pred_c))
print("confusion matrix:\n",confusion_matrix(y_test_c, y_pred_c))

#cross validation
cv_scores = cross_val_score(rf_model, x_clf, y_clf, cv=5)
print("Cross Validation Accuracy:", cv_scores.mean())

#plot - 5 : Feature Importance
importance = rf_model.feature_importances_
feature_names = x_clf.columns

plt.figure()
plt.bar(feature_names, importance)
plt.xticks(rotation=45)
plt.title("Feature Importance - Attriton Model")
plt.show()

print("\nProject Completed Successfully!")